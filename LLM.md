# ğŸ“˜ LLM Textbook Index

A structured overview of NLP topics covered in below.
Follow the link for full practice code on all LLM topics: [LLM Code Repo]()

| ğŸ“ **Topic Name**      | ğŸ“‚ **Type**       | ğŸ“š **Main Topic**    |
|------------------------|--------------------|-----------------------|
|[1. Transformer architecture](https://github.com/ramasureshvijjana/LLM/blob/master/01_Transformer_architecture.md)|  Topic| âœ… |
|[2. Pre-training and Fine-tuning]()|  Topic| âœ… |
|[3. Input Token Embedding Techniques]() |  Topic| âœ… |
|                        |                    |                       |
|                        |                    |                       |

> âœ¨ *Tip: Use consistent naming and categorization to keep your index organized and searchable.*
>
| ğŸ“ **Topic Name**      | ğŸ“‚ **Type**       | ğŸ“š **Main Topic**    |
|------------------------|-------------------|-----------------------|
|[1. Transformer architecture](https://github.com/ramasureshvijjana/LLM/blob/master/01_Transformer_architecture.md)| &emsp;Topic | &emsp;âœ… |
|[2. Pre-training and Fine-tuning]()| &emsp;Topic | &emsp;âœ… |
|[3. Input Token Embedding Techniques]() <br>&emsp;[3.1 Word Embeddings]() <br>&emsp;[3.2 Positional Embeddings]() <br>&emsp;[3.3 Subword Embeddings]()| &emsp;Topic <br>&emsp;Topic <br>&emsp;Topic <br>&emsp;Topic  | &emsp;âœ… <br>&emsp;âœ… <br>&emsp;âœ… <br>&emsp;âœ… <br>&emsp;|


